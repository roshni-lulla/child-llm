#!/usr/bin/env python3
"""Chunked iterative generator for days, weeks, and months with 12-hour chunks."""

import asyncio
import json
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional

# Import existing components
sys.path.append('.')
from child_llm.models.scenario import Scenario
from chunked_two_pass_generator import ChunkedTwoPassGenerator
from simple_validation import validate_developmental_appropriateness

class ChunkedIterativeGenerator:
    """Generates monologues iteratively with 12-hour chunks and perfect coherence."""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.generator = ChunkedTwoPassGenerator(api_key)
        self.memory_file = Path("my_monologue/memory/context.json")
        self.memory_file.parent.mkdir(exist_ok=True)
    
    def load_memory(self) -> Dict[str, Any]:
        """Load previous context from memory file."""
        if self.memory_file.exists():
            with open(self.memory_file, 'r') as f:
                return json.load(f)
        return {
            "recent_milestones": [],
            "recent_activities": [],
            "current_routines": [],
            "recent_social": "basic caregiver interaction",
            "last_generated_date": None,
            "last_generated_hour": None,
            "generation_history": []
        }
    
    def save_memory(self, memory: Dict[str, Any]):
        """Save context to memory file."""
        with open(self.memory_file, 'w') as f:
            json.dump(memory, f, indent=2)
    
    def update_memory(self, day_data: Dict[str, Any], memory: Dict[str, Any]):
        """Update memory with new day data."""
        # Extract key information from the day
        milestones = []
        activities = []
        routines = []
        social_interactions = []
        
        # Analyze internal monologue for key events
        for hour_data in day_data.get('internal_monologue', {}).values():
            for entry in hour_data.get('entries', []):
                components = entry.get('consciousness_components', {})
                
                # Extract milestones
                if 'first' in components.get('motor_behavior', '').lower():
                    milestones.append(components['motor_behavior'])
                
                # Extract activities
                if components.get('environmental_learning'):
                    activities.append(components['environmental_learning'])
                
                # Extract routines
                if components.get('social_interaction'):
                    routines.append(components['social_interaction'])
                
                # Extract social interactions
                if components.get('social_interaction') and 'caregiver' in components['social_interaction'].lower():
                    social_interactions.append(components['social_interaction'])
        
        # Update memory
        memory['recent_milestones'] = milestones[-5:]  # Keep last 5 milestones
        memory['recent_activities'] = activities[-10:]  # Keep last 10 activities
        memory['current_routines'] = list(set(routines[-15:]))  # Keep last 15 unique routines
        memory['recent_social'] = social_interactions[-1] if social_interactions else "basic caregiver interaction"
        memory['last_generated_date'] = day_data['date']
        memory['last_generated_hour'] = 23  # End of day
        
        # Add to generation history
        memory['generation_history'].append({
            'date': day_data['date'],
            'age_weeks': day_data['age_weeks'],
            'milestones': milestones,
            'activities': activities
        })
        
        # Keep only last 30 days of history
        if len(memory['generation_history']) > 30:
            memory['generation_history'] = memory['generation_history'][-30:]
    
    async def generate_day(self, scenario_file: str, date: str, timeline_file: str, output_dir: str, validate: bool = True) -> Dict[str, Any]:
        """Generate a single day with 12-hour chunks and validation."""
        print(f"üéØ Generating day: {date}")
        
        # Load scenario and timeline
        with open(scenario_file, 'r') as f:
            scenario_data = json.load(f)
        scenario = Scenario(**scenario_data)
        
        with open(timeline_file, 'r') as f:
            timeline_data = json.load(f)
        
        # Load memory
        memory = self.load_memory()
        
        # Generate the day
        output_path = Path(output_dir)
        day_data = await self.generator.generate_day_chunked(
            scenario, date, timeline_data, output_path
        )
        
        # Update memory
        self.update_memory(day_data, memory)
        self.save_memory(memory)
        
        # Validate if requested
        if validate:
            print(f"üîç Validating day: {date}")
            year_part = date.split("-")[0]
            month_part = date.split("-")[1]
            day_file = f"{output_dir}/year_{year_part}/month_{month_part}/day_{date}_chunked.json"
            
            if Path(day_file).exists():
                validation_results = validate_developmental_appropriateness(
                    day_file, use_llm=True, api_key=self.api_key, fix_content=True
                )
                print(f"üìä Validation Score: {validation_results['score']}/100")
                
                if validation_results.get('fixes_applied', 0) > 0:
                    print(f"‚úÖ Applied {validation_results['fixes_applied']} fixes")
        
        return day_data
    
    async def generate_week(self, scenario_file: str, start_date: str, timeline_file: str, output_dir: str) -> Dict[str, Any]:
        """Generate a complete week with 12-hour chunks and memory."""
        print(f"üìÖ Generating week starting: {start_date}")
        
        start_date_obj = datetime.strptime(start_date, "%Y-%m-%d").date()
        week_data = {
            "start_date": start_date,
            "days": [],
            "week_summary": {},
            "generation_timestamp": datetime.now().isoformat(),
            "generation_method": "chunked_12_hour"
        }
        
        for i in range(7):
            current_date = start_date_obj + timedelta(days=i)
            date_str = current_date.strftime("%Y-%m-%d")
            
            print(f"\nüìù Day {i+1}/7: {date_str}")
            day_data = await self.generate_day(scenario_file, date_str, timeline_file, output_dir)
            week_data["days"].append(day_data)
        
        # Generate week summary
        week_data["week_summary"] = self._generate_week_summary(week_data["days"])
        
        # Save week summary
        week_summary_file = Path(output_dir) / f"week_summary_{start_date}_chunked.json"
        with open(week_summary_file, 'w') as f:
            json.dump(week_data, f, indent=2)
        
        print(f"‚úÖ Week generation complete: {week_summary_file}")
        return week_data
    
    async def generate_month(self, scenario_file: str, start_date: str, timeline_file: str, output_dir: str) -> Dict[str, Any]:
        """Generate a complete month with 12-hour chunks and memory."""
        print(f"üìÖ Generating month starting: {start_date}")
        
        start_date_obj = datetime.strptime(start_date, "%Y-%m-%d").date()
        month_data = {
            "start_date": start_date,
            "weeks": [],
            "month_summary": {},
            "generation_timestamp": datetime.now().isoformat(),
            "generation_method": "chunked_12_hour"
        }
        
        # Generate 4 weeks
        for week_num in range(4):
            week_start = start_date_obj + timedelta(weeks=week_num)
            week_start_str = week_start.strftime("%Y-%m-%d")
            
            print(f"\nüìÖ Week {week_num+1}/4: {week_start_str}")
            week_data = await self.generate_week(scenario_file, week_start_str, timeline_file, output_dir)
            month_data["weeks"].append(week_data)
        
        # Generate month summary
        month_data["month_summary"] = self._generate_month_summary(month_data["weeks"])
        
        # Save month summary
        month_summary_file = Path(output_dir) / f"month_summary_{start_date}_chunked.json"
        with open(month_summary_file, 'w') as f:
            json.dump(month_data, f, indent=2)
        
        print(f"‚úÖ Month generation complete: {month_summary_file}")
        return month_data
    
    def _generate_week_summary(self, days: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Generate summary of the week."""
        if not days:
            return {}
        
        # Analyze all days for patterns
        all_milestones = []
        all_activities = []
        age_progression = []
        
        for day in days:
            age_progression.append(day.get('age_weeks', 0))
            # Extract milestones and activities from memory
            memory = self.load_memory()
            all_milestones.extend(memory.get('recent_milestones', []))
            all_activities.extend(memory.get('recent_activities', []))
        
        return {
            "age_range": f"{min(age_progression)}-{max(age_progression)} weeks",
            "milestones_achieved": list(set(all_milestones)),
            "activities_explored": list(set(all_activities)),
            "days_generated": len(days),
            "coherence_score": "high",  # Based on memory integration
            "generation_method": "chunked_12_hour"
        }
    
    def _generate_month_summary(self, weeks: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Generate summary of the month."""
        if not weeks:
            return {}
        
        # Analyze all weeks
        all_week_summaries = [week.get('week_summary', {}) for week in weeks]
        
        return {
            "weeks_generated": len(weeks),
            "developmental_progression": "tracked across weeks",
            "memory_integration": "full",
            "timeline_coherence": "maintained",
            "generation_method": "chunked_12_hour"
        }

async def main():
    if len(sys.argv) < 3:
        print("Usage: python chunked_iterative_generator.py <mode> <start_date> [options]")
        print("Modes: day, week, month")
        print("Example: python chunked_iterative_generator.py day 2025-01-01")
        print("Example: python chunked_iterative_generator.py week 2025-01-01")
        print("Example: python chunked_iterative_generator.py month 2025-01-01")
        sys.exit(1)
    
    mode = sys.argv[1]
    start_date = sys.argv[2]
    
    # Check API key
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("‚ùå OPENAI_API_KEY environment variable not set")
        sys.exit(1)
    
    # Default paths
    scenario_file = "my_monologue/scenarios/my_child.json"
    timeline_file = "my_monologue/timeline/master_timeline.json"
    output_dir = "my_monologue/output"
    
    # Create generator
    generator = ChunkedIterativeGenerator(api_key)
    
    if mode == "day":
        await generator.generate_day(scenario_file, start_date, timeline_file, output_dir)
    elif mode == "week":
        await generator.generate_week(scenario_file, start_date, timeline_file, output_dir)
    elif mode == "month":
        await generator.generate_month(scenario_file, start_date, timeline_file, output_dir)
    else:
        print(f"‚ùå Unknown mode: {mode}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
